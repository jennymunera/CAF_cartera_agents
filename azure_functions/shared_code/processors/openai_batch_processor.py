import os
import json
import logging
import re
import time
import tempfile
from typing import Dict, List, Any, Optional
from datetime import datetime
from pathlib import Path
from openai import AzureOpenAI
from shared_code.utils.app_insights_logger import get_logger
from shared_code.utils.blob_storage_client import BlobStorageClient

# Prompts como constantes
PROMPT_AUDITORIA = """prompt - Agente Auditoria

Eres un Analista experto en documentos de auditoria, debes Extraer todas las variables del formato Auditor√≠as priorizando archivos IXP, normalizando los campos categ√≥ricos y emitir un concepto final (Favorable / Favorable con reservas / Desfavorable) con justificaci√≥n.

Prioridad documental: 

Solo documentos cuyo nombre inicia con IXP.

Si hay m√∫ltiples versiones, usa la m√°s reciente y registra cambios en Observaci√≥n.

Checklist anti‚Äì"NO EXTRAIDO" (agotar antes de rendirse): 

Portada / primeras 2 p√°ginas ‚Üí "C√≥digo de operaci√≥n", CFA/CFX.

√çndice ‚Üí saltos a "Opini√≥n", "Dictamen", "Conclusi√≥n".

Secciones v√°lidas de concepto ‚Üí Opini√≥n, Opini√≥n sin reserva/sin salvedades, Dictamen, Conclusi√≥n de auditor√≠a (acepta variantes ES/PT/EN: "Opinion", "Unqualified opinion", "Parecer", "Sem ressalvas").

Tablas/seguimiento administrativo ‚Üí Estado del informe, Fecha de vencimiento, Fecha de cambio de estado (seg√∫n SSC o tabla del doc).

Encabezados/pies ‚Üí "√öltima revisi√≥n/Actualizaci√≥n".

Anexos del auditor / "Carta de gerencia".

Elegir versi√≥n m√°s reciente; Observaci√≥n = campo: valor_anterior ‚Üí valor_nuevo (doc_origen ‚Üí doc_nuevo).

D√≥nde buscar (por campo): 

C√≥digo CFA: portada/primeras p√°ginas ("C√≥digo de operaci√≥n", "CFA", "codigo CFA").

c√≥digo CFX: cerca de CFA, diferente al CFA, en cabeceras administrativas.

Estado del informe: tablas/seguimiento (normal, vencido, dispensado, satisfecho).

Si se entreg√≥ informe de auditor√≠a externo: menciones expl√≠citas de entrega/recepci√≥n/dispensa.

Concepto Control interno: solo en Opini√≥n/Dictamen/Conclusi√≥n; frases sobre suficiencia/deficiencias de control interno.

Concepto licitaci√≥n de proyecto: en Opini√≥n/Dictamen; adquisiciones/contrataciones/procurement.

Concepto uso de recursos: en Opini√≥n/Dictamen; conformidad/desv√≠os respecto al plan.

Concepto sobre unidad ejecutora: en Opini√≥n/Dictamen; desempe√±o de la UGP.

Fecha de vencimiento / cambio de estado: tablas administrativas/SSC.

Fecha de extracci√≥n: ahora (fecha-hora del sistema).

Fecha de √∫ltima revisi√≥n: encabezados/pies ("√öltima revisi√≥n/Actualizaci√≥n").

status auditor√≠a: "disponible/ no disponible/ no requerido/ pendiente".

Nombre del archivo revisado: archivo base del dato final.

texto justificaci√≥n: 1‚Äì2 frases de Opini√≥n/Dictamen que sustenten los conceptos.

Observaci√≥n: diferencias entre versiones.

Sin√≥nimos √∫tiles (flexibles)

Estado: estado, estatus, situaci√≥n, condici√≥n.

Opini√≥n: dictamen, conclusiones, parecer.

Entrega informe externo: entregado, recibido, presentado, publicado en SSC, dispensa.

Niveles de confianza (adj√∫ntalos por campo): 

EXTRAIDO_DIRECTO (evidencia literal), EXTRAIDO_INFERIDO (sin√≥nimo/contexto), NO_EXTRAIDO.
Formato por valor: valor|NIVEL_CONFIANZA.

Normalizaci√≥n + Concepto: 

estado_informe_norm ‚àà {dispensado, normal, satisfecho, vencido} o null.

informe_externo_entregado_norm ‚àà {a tiempo, dispensado, vencido} o null.

concepto_control_interno_norm, concepto_licitacion_norm, concepto_uso_recursos_norm, concepto_unidad_ejecutora_norm ‚àà {Favorable, Favorable con reservas, Desfavorable, no se menciona}.

concepto_final ‚àà {Favorable, Favorable con reservas, Desfavorable} + concepto_rationale (1‚Äì2 frases con cita corta).

Few-shot (mapeos r√°pidos): 

"sin salvedades‚Ä¶ no revel√≥ deficiencias significativas de control interno" ‚Üí Control interno = Favorable.

"excepto por‚Ä¶" / "con salvedades‚Ä¶" ‚Üí concepto = Favorable con reservas.

"se sostienen las observaciones / deficiencias" ‚Üí concepto = Desfavorable.

Salida (todas las claves; si falta evidencia, "NO EXTRAIDO")
C√≥digo CFA, Estado del informe, Si se entreg√≥ informe de auditor√≠a externo, Concepto Control interno, Concepto licitaci√≥n de proyecto, Concepto uso de recursos financieros seg√∫n lo planificado, Concepto sobre unidad ejecutora, Fecha de vencimiento, Fecha de cambio del estado del informe, Fecha de extracci√≥n, Fecha de ultima revisi√≥n, status auditor√≠a, c√≥digo CFX, Nombre del archivo revisado, texto justificaci√≥n, Observaci√≥n, estado_informe_norm, informe_externo_entregado_norm, concepto_control_interno_norm, concepto_licitacion_norm, concepto_uso_recursos_norm, concepto_unidad_ejecutora_norm, concepto_final, concepto_rationale"""

PROMPT_DESEMBOLSOS = """Prompt ‚Äî Agente Desembolsos 

Eres un analista de cartera experto en seguimiento de desembolsos, debes Extraer desembolsos proyectados y realizados, con tabla-primero, deduplicando por per√≠odo+moneda, sin convertir moneda. Normaliza fuente y emite concepto final con justificaci√≥n.

Prioridad documental
ROP > INI > DEC:

Proyectados: en Cronograma/Programaci√≥n/Calendario (ROP/INI).

Realizados: "Detalle/Estado de desembolsos", EEFF o narrativa (si aparece).

Checklist anti‚Äì"NO EXTRAIDO": 

Tablas (cronograma/estado/flujo de caja).

Columnas t√≠picas: Fecha | Monto | Moneda | Fuente/Tipo.

Equivalente USD: solo llenarlo si no existe la moneda original como registro separado.

DEDUP: no repitas mismo per√≠odo + moneda del mismo evento.

Si falta alg√∫n dato (fecha/moneda/monto/fuente) tras revisar tablas y notas ‚Üí NO EXTRAIDO.

D√≥nde buscar (por campo): 

C√≥digo de operaci√≥n (CFX): portada/primeras p√°ginas, cabecera del cronograma.

fecha de desembolso por parte de CAF:

Realizado ‚Üí "Detalle/Estado de desembolsos", "Desembolsos efectuados/realizados".

Proyectado ‚Üí "Cronograma/Programaci√≥n/Calendario de desembolsos", "Flujo de caja".

monto desembolsado CAF: columna "Monto/Importe/Desembolsado" (sin s√≠mbolos, sin conversiones).

monto desembolsado CAF USD: solo si hay columna/registro expl√≠cito en USD y no existe el original.

fuente CAF: etiqueta clara: "CAF Realizado", "Proyectado (Cronograma)", "Anticipo", "Pago directo", etc.

fecha de extracci√≥n (ahora), fecha de √∫ltima revisi√≥n, Nombre del archivo revisado, Observaci√≥n (cambios de montos/periodificaci√≥n/moneda/fuente entre versiones).

Niveles de confianza: 

EXTRAIDO_DIRECTO, EXTRAIDO_INFERIDO, NO_EXTRAIDO (usa valor|NIVEL_CONFIANZA).

Normalizaci√≥n + Concepto: 

fuente_norm (opcional) ‚Üí {CAF Realizado, Proyectado (Cronograma), Anticipo, Pago directo, Reembolso‚Ä¶} o null.

concepto_final ‚àà {Favorable, Favorable con reservas, Desfavorable}:

Favorable: registros completos y coherentes (fecha, monto, moneda, fuente).

Con reservas: inconsistencias menores explicadas o diferencias programado/realizado documentadas.

Desfavorable: faltantes graves/errores o retrasos sin justificaci√≥n.

concepto_rationale: 1‚Äì2 frases con evidencia (indicar fuente: ROP/INI/DEC/EEFF).

Few-shot (patrones de montos/fechas): 

2024-06 | 1.250.000 | USD | CAF Realizado ‚Üí fecha="2024-06"|EXTRAIDO_DIRECTO, monto="1250000"|EXTRAIDO_DIRECTO, USD, fuente="CAF Realizado"|EXTRAIDO_DIRECTO.

"USD 1,000", "1.000.000", "1 000 000", "US$ 2,5 M" ‚Üí extrae n√∫mero puro (no agregues s√≠mbolos; no conviertas).

Reglas claves: 

No convertir moneda ni inferir fechas/moneda.

No duplicar periodo+moneda.

Priorizar moneda original; USD solo si no est√° la original.

Salida (si falta evidencia, "NO EXTRAIDO")
C√≥digo de operaci√≥n (CFX), fecha de desembolso por parte de CAF, monto desembolsado CAF, monto desembolsado CAF USD, fuente CAF proyectado, fecha de extracci√≥n, fecha de ultima revisi√≥n, Nombre del archivo revisado, Observaci√≥n, fuente_norm (opcional), concepto_final, concepto_rationale."""

PROMPT_PRODUCTOS = """Prompt ‚Äî Agente Productos 


Eres un Analista de Cartera, Experto en seguimiento documentos de proyectos, debes Identificar todos los productos comprometidos en el proyecto y genera una fila por producto, priorizando fuentes y separando meta (n√∫mero) y unidad. Normaliza campos y emite concepto final por producto con justificaci√≥n.

Prioridad documental
ROP > INI > DEC > IFS (y anexo Excel si lo cita el √≠ndice). En duplicados, usar versi√≥n m√°s reciente; cambios ‚Üí Observaci√≥n.

Checklist anti‚Äì"NO EXTRAIDO":

Tablas/Matrices: "Matriz de Indicadores", "Marco L√≥gico", "Metas f√≠sicas".

Narrativo: "Resultados esperados", "Componentes", "Seguimiento de indicadores" (IFS).

Anexos/Excel de indicadores.

Encabezados/pies ‚Üí "√öltima revisi√≥n/Actualizaci√≥n".

Validar que el registro sea producto (no resultado).

D√≥nde buscar (por campo): 

C√≥digo CFA / c√≥digo CFX: portada/primeras p√°ginas, marcos l√≥gicos, car√°tulas (ROP/INI/DEC/IFS).

descripci√≥n de producto: t√≠tulos/filas en matrices/POA/Componentes/IFS.

meta del producto / meta unidad: columnas de meta ("230 km" ‚Üí meta="230", unidad="km"). Si no es inequ√≠voco ‚Üí NO EXTRAIDO.

fuente del indicador: columna/nota "Fuente" (ej.: ROP, INI, DEC, IFS, SSC).

fecha cumplimiento de meta: "Fecha meta / Fecha de cumplimiento / Plazo".

tipo de dato: pendiente/proyectado/realizado (detecta palabras clave como programado, estimado, alcanzado).

caracter√≠stica ‚àà {administraci√≥n, capacitaci√≥n, equipamiento y mobiliario, fortalecimiento institucional, infraestructura}.

check_producto: "S√≠" si el indicador es relacionado al producto y est√° extra√≠do.

fecha de ultima revisi√≥n, Nombre del archivo revisado, Retraso (S√≠ si fecha efectiva > fecha meta), Observaci√≥n.

Casos / reglas especiales: 

Acumulado vs per√≠odo: si la tabla es acumulativa, no dupliques.

Idiomas/formatos: acepta ES/PT/EN y tablas rotadas.

Separaci√≥n meta/unidad: detecta variantes ("230 kil√≥metros", "230,5 Km", "100%", "1.500 personas").

No inventes: si faltan meta o unidad, deja NO EXTRAIDO.

Niveles de confianza: 

EXTRAIDO_DIRECTO, EXTRAIDO_INFERIDO, NO_EXTRAIDO. Formato: valor|NIVEL_CONFIANZA.

Normalizaci√≥n + Concepto: 

tipo_dato_norm ‚àà {pendiente, proyectado, realizado} o null.

caracteristica_norm ‚àà {administracion, capacitacion, fortalecimiento institucional, infraestructura} o null.

meta_num: n√∫mero puro si inequ√≠voco; si no, null.

meta_unidad_norm: normalizar a cat√°logo (%, km, personas, metros cuadrados, metros cubicos, horas,hectareas, kilovoltioamperio, megavoltio amperio, litros/segundo, galones, miles de galones por dia, toneladas, cantidad/ a√±o, miles de metros al cuadrado, etc.).

concepto_final ‚àà {Favorable, Favorable con reservas, Desfavorable} seg√∫n coherencia meta/fecha/Retraso + fuente; concepto_rationale (1‚Äì2 frases con evidencia y fuente).

Few-shot (patrones t√≠picos): 

"230 km de carretera" ‚Üí meta="230"|EXTRAIDO_DIRECTO, unidad="km"|EXTRAIDO_DIRECTO.

"1,500 personas capacitadas" ‚Üí meta="1500"|EXTRAIDO_DIRECTO, unidad="personas"|EXTRAIDO_DIRECTO.

"Resultado alcanzado" ‚Üí tipo_dato="realizado"|EXTRAIDO_DIRECTO.

"Meta programada para 2024" ‚Üí tipo_dato="proyectado"|EXTRAIDO_INFERIDO.

"Talleres de capacitaci√≥n" ‚Üí caracter√≠stica="capacitaci√≥n"|EXTRAIDO_INFERIDO.

Salida (una fila por producto; si falta evidencia, "NO EXTRAIDO")
C√≥digo CFA, descripci√≥n de producto, meta del producto, meta unidad, fuente del indicador, fecha cumplimiento de meta, tipo de dato, caracter√≠stica, check_producto, fecha de extracci√≥n, fecha de ultima revisi√≥n, c√≥digo CFX, Nombre del archivo revisado, Retraso, Observaci√≥n, tipo_dato_norm, caracteristica_norm, meta_num, meta_unidad_norm, concepto_final, concepto_rationale."""

# Configurar logging para reducir verbosidad de Azure
logging.getLogger('azure.core.pipeline.policies.http_logging_policy').setLevel(logging.WARNING)
logging.getLogger('azure').setLevel(logging.WARNING)
logging.getLogger('openai').setLevel(logging.WARNING)

class OpenAIBatchProcessor:
    """
    Procesador de Azure OpenAI Batch API para an√°lisis de documentos.
    Genera batch jobs para procesar documentos y chunks usando 3 prompts espec√≠ficos.
    """
    
    def __init__(self):
        self.logger = get_logger('openai_batch_processor')
        self._setup_client()
        self._load_prompts()
        
    def _setup_client(self):
        """Configura el cliente de Azure OpenAI usando variables de entorno."""
        try:
            # Obtener configuraci√≥n del .env
            api_key = os.getenv('AZURE_OPENAI_API_KEY')
            endpoint = os.getenv('AZURE_OPENAI_ENDPOINT', 'https://oai-poc-idatafactory-cr.openai.azure.com/')
            api_version = os.getenv('AZURE_OPENAI_API_VERSION', '2025-04-01-preview')
            self.deployment_name = os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME', 'gpt-4o-2')
            
            if not api_key:
                raise ValueError("AZURE_OPENAI_API_KEY no encontrada en variables de entorno")
            
            self.client = AzureOpenAI(
                api_version=api_version,
                azure_endpoint=endpoint,
                api_key=api_key
            )
            
            self.logger.info(f"Cliente Azure OpenAI Batch configurado exitosamente")
            self.logger.info(f"Endpoint: {endpoint}")
            self.logger.info(f"Deployment: {self.deployment_name}")
            
        except Exception as e:
            self.logger.error(f"Error configurando cliente Azure OpenAI: {str(e)}")
            raise
    
    def _load_prompts(self):
        """Carga los prompts desde constantes definidas en el c√≥digo"""
        try:
            # Asignar prompts a atributos de instancia para compatibilidad
            self.prompt_auditoria = PROMPT_AUDITORIA
            self.prompt_desembolsos = PROMPT_DESEMBOLSOS
            self.prompt_productos = PROMPT_PRODUCTOS
            
            # Crear diccionario de prompts para acceso por n√∫mero
            self.prompts = {
                'prompt_1': PROMPT_PRODUCTOS,
                'prompt_2': PROMPT_DESEMBOLSOS, 
                'prompt_3': PROMPT_AUDITORIA
            }
            
            self.logger.info("‚úÖ Prompts cargados exitosamente desde constantes")
            
        except Exception as e:
            self.logger.error(f"Error cargando prompts: {str(e)}")
            raise
    
    def _get_document_prefix(self, document_content: Dict[str, Any]) -> str:
        """
        Extrae el prefijo del documento basado en el nombre del archivo.
        
        Args:
            document_content: Contenido del documento
            
        Returns:
            Prefijo del documento en may√∫sculas (ej: 'IXP', 'ROP', 'INI')
        """
        # Obtener nombre del documento
        document_name = document_content.get('document_name', document_content.get('filename', ''))
        
        # Si es un chunk, obtener el nombre base
        if '_chunk_' in document_name:
            document_name = document_name.split('_chunk_')[0]
        
        # Extraer prefijo (primeras 3 letras antes del primer gui√≥n)
        if '-' in document_name:
            prefix = document_name.split('-')[0].upper()
        else:
            # Si no hay gui√≥n, tomar las primeras 3 letras
            prefix = document_name[:3].upper()
        
        return prefix
    
    def _should_process_with_prompt(self, document_content: Dict[str, Any], prompt_number: int) -> bool:
        """
        Determina si un documento debe ser procesado con un prompt espec√≠fico.
        
        Args:
            document_content: Contenido del documento
            prompt_number: N√∫mero del prompt (1, 2, 3)
            
        Returns:
            True si debe procesarse, False si no
        """
        document_prefix = self._get_document_prefix(document_content)
        
        # Filtros por prefijo seg√∫n prompt
        if prompt_number == 1:  # Auditor√≠a
            allowed_prefixes = ['IXP']
        elif prompt_number == 2:  # Productos
            allowed_prefixes = ['ROP', 'INI', 'DEC', 'IFS']
        elif prompt_number == 3:  # Desembolsos
            allowed_prefixes = ['ROP', 'INI', 'DEC']
        else:
            return False
        
        return document_prefix in allowed_prefixes
    
    def _create_batch_request(self, custom_id: str, prompt: str, content: str) -> Dict[str, Any]:
        """
        Crea una request individual para el batch job.
        
        Args:
            custom_id: ID √∫nico para identificar la request
            prompt: Prompt a usar
            content: Contenido del documento
            
        Returns:
            Dict con la estructura de request para batch
        """
        return {
            "custom_id": custom_id,
            "method": "POST",
            "url": "/chat/completions",
            "body": {
                "model": self.deployment_name,
                "messages": [
                    {
                        "role": "system", 
                        "content": "Eres un Analista experto en documentos de auditor√≠a. Tu tarea es extraer informaci√≥n espec√≠fica siguiendo un formato estructurado y emitiendo conceptos normalizados para entregar en formato JSON lo solicitado."
                    },
                    {
                        "role": "user", 
                        "content": f"{prompt}\n\nDocumento:\n{content}"
                    }
                ],
                "max_completion_tokens": 1000,
                "temperature": 0.3
            }
        }
    
    def create_batch_job(self, project_name: str) -> Dict[str, Any]:
        """
        Crea un batch job para procesar todos los documentos de un proyecto usando BlobStorageClient.
        
        Args:
            project_name: Nombre del proyecto (ej: CFA009660)
            
        Returns:
            Dict con informaci√≥n del batch job creado
        """
        self.logger.info(f"üöÄ Creando batch job para proyecto: {project_name}")
        
        batch_requests = []
        documents_info = []
        
        try:
            blob_client = BlobStorageClient()
            
            # Procesar documentos DI desde blob storage
            di_documents = blob_client.list_processed_documents(project_name)
            for doc_name in di_documents:
                if doc_name.endswith('.json'):
                    self._add_document_to_batch_from_blob(doc_name, project_name, batch_requests, documents_info, blob_client, 'DI')
            
            # Procesar chunks desde blob storage
            chunk_documents = blob_client.list_chunks(project_name)
            for chunk_name in chunk_documents:
                if chunk_name.endswith('.json'):
                    self._add_document_to_batch_from_blob(chunk_name, project_name, batch_requests, documents_info, blob_client, 'chunks')
            
            if not batch_requests:
                raise ValueError(f"No se encontraron documentos para procesar en proyecto {project_name}")
            
            # Crear archivo JSONL temporal (formato requerido por Azure Batch API)
            import tempfile
            with tempfile.NamedTemporaryFile(mode='w', suffix='.jsonl', delete=False, encoding='utf-8') as f:
                for request in batch_requests:
                    f.write(json.dumps(request, ensure_ascii=False) + '\n')
                batch_input_file = f.name
            
            self.logger.info(f"üìÑ Archivo batch temporal creado: {batch_input_file} ({len(batch_requests)} requests)")
            
            # Subir archivo a Azure
            uploaded = self.client.files.create(
                file=open(batch_input_file, "rb"),
                purpose="batch"
            )
            
            # Limpiar archivo temporal
            os.unlink(batch_input_file)
            
            # Crear batch job
            batch = self.client.batches.create(
                input_file_id=uploaded.id,
                endpoint="/chat/completions",
                completion_window="24h",
                metadata={"project": project_name}
            )
            
            batch_info = {
                "batch_id": batch.id,
                "project_name": project_name,
                "input_file_id": uploaded.id,
                "created_at": datetime.now().isoformat(),
                "status": batch.status,
                "total_requests": len(batch_requests),
                "documents_info": documents_info
            }
            
            # Guardar informaci√≥n del batch en blob storage
            batch_info_content = json.dumps(batch_info, indent=2, ensure_ascii=False)
            batch_info_path = f"basedocuments/{project_name}/processed/openai_logs/batch_info_{project_name}_{batch.id}.json"
            blob_client.upload_blob(batch_info_path, batch_info_content)
            
            self.logger.info(f"‚úÖ Batch job creado exitosamente:")
            self.logger.info(f"   üìã Batch ID: {batch.id}")
            self.logger.info(f"   üìä Total requests: {len(batch_requests)}")
            self.logger.info(f"   üìÅ Info guardada en blob: {batch_info_path}")
            
            return batch_info
            
        except Exception as e:
            self.logger.error(f"Error creando batch job: {str(e)}")
            raise
    
    def process_chunks(self, chunks: List[Dict], document_name: str, queue_type: str) -> Dict[str, Any]:
        """
        Procesa chunks directamente para crear un batch job.
        
        Args:
            chunks: Lista de chunks del documento
            document_name: Nombre del documento
            queue_type: Tipo de cola (no usado, mantenido por compatibilidad)
            
        Returns:
            Dict con informaci√≥n del batch job creado
        """
        try:
            self.logger.info(f"üöÄ Procesando {len(chunks)} chunks para documento: {document_name}")
            
            batch_requests = []
            documents_info = []
            
            for i, chunk in enumerate(chunks):
                # Crear contenido del chunk con informaci√≥n del documento
                chunk_content = {
                    'content': chunk.get('content', ''),
                    'document_name': document_name,
                    'chunk_index': i
                }
                
                content_text = chunk_content.get('content', '')
                
                doc_info = {
                    "document_name": document_name,
                    "chunk_index": i,
                    "prefix": self._get_document_prefix(chunk_content),
                    "prompts_applied": []
                }
                
                # Verificar y agregar prompts aplicables
                prompts = [
                    (1, "auditoria", self.prompt_auditoria),
                    (2, "desembolsos", self.prompt_desembolsos),
                    (3, "productos", self.prompt_productos)
                ]
                
                for prompt_num, prompt_type, prompt_text in prompts:
                    if self._should_process_with_prompt(chunk_content, prompt_num):
                        custom_id = f"{document_name}_{prompt_type}_chunk_{i:03d}"
                        
                        request = self._create_batch_request(custom_id, prompt_text, content_text)
                        batch_requests.append(request)
                        doc_info["prompts_applied"].append(prompt_type)
                
                if doc_info["prompts_applied"]:
                    documents_info.append(doc_info)
                    self.logger.info(f"üìÑ Chunk {i} agregado al batch (prompts: {doc_info['prompts_applied']})")
            
            if not batch_requests:
                raise ValueError(f"No se generaron requests para el documento {document_name}")
            
            # Crear archivo JSONL temporal
            temp_batch_file = f"/tmp/batch_input_{document_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jsonl"
            
            with open(temp_batch_file, 'w', encoding='utf-8') as f:
                for request in batch_requests:
                    f.write(json.dumps(request, ensure_ascii=False) + '\n')
            
            self.logger.info(f"üìÑ Archivo batch temporal creado: {temp_batch_file} ({len(batch_requests)} requests)")
            
            # Subir archivo a Azure
            uploaded = self.client.files.create(
                file=open(temp_batch_file, "rb"),
                purpose="batch"
            )
            
            # Crear batch job
            batch = self.client.batches.create(
                input_file_id=uploaded.id,
                endpoint="/chat/completions",
                completion_window="24h",
                metadata={"document": document_name}
            )
            
            batch_info = {
                "batch_id": batch.id,
                "document_name": document_name,
                "input_file_id": uploaded.id,
                "input_file_name": temp_batch_file,
                "created_at": datetime.now().isoformat(),
                "status": batch.status,
                "total_requests": len(batch_requests),
                "documents_info": documents_info
            }
            
            self.logger.info(f"‚úÖ Batch job creado exitosamente:")
            self.logger.info(f"   üìã Batch ID: {batch.id}")
            self.logger.info(f"   üìä Total requests: {len(batch_requests)}")
            
            # Limpiar archivo temporal
            try:
                os.remove(temp_batch_file)
            except:
                pass
            
            return batch_info
            
        except Exception as e:
            self.logger.error(f"Error procesando chunks: {str(e)}")
            raise

    def _add_document_to_batch_from_blob(self, doc_name: str, project_name: str, batch_requests: List[Dict], documents_info: List[Dict], blob_client: BlobStorageClient, doc_type: str):
        """
        A√±ade un documento desde blob storage al batch job.
        
        Args:
            doc_name: Nombre del documento
            project_name: Nombre del proyecto
            batch_requests: Lista de requests del batch
            documents_info: Lista de informaci√≥n de documentos
            blob_client: Cliente de blob storage
            doc_type: Tipo de documento ('DI' o 'chunks')
        """
        try:
            # Determinar la subcarpeta seg√∫n el tipo
            if doc_type == 'DI':
                subfolder = 'DI'
            else:  # chunks
                subfolder = 'chunks'
            
            # Descargar contenido del blob usando el m√©todo correcto
            doc_data = blob_client.load_processed_document(project_name, subfolder, doc_name)
            if not doc_data:
                self.logger.warning(f"No se pudo descargar el documento: {doc_name} desde {subfolder}")
                return
            
            # Asegurar que el nombre del documento est√© en los datos
            if 'document_name' not in doc_data and 'filename' not in doc_data:
                doc_data['document_name'] = doc_name
            
            # Obtener prefijo del documento
            prefix = self._get_document_prefix(doc_data)
            self.logger.info(f"üîç Documento: {doc_name}, Prefijo extra√≠do: {prefix}")
            
            # Procesar con cada prompt seg√∫n las reglas
            prompts_applied = []
            
            for prompt_num in [1, 2, 3]:
                should_process = self._should_process_with_prompt(doc_data, prompt_num)
                self.logger.info(f"üìã Prompt {prompt_num} para {doc_name}: {'‚úÖ S√ç' if should_process else '‚ùå NO'}")
                if should_process:
                    custom_id = f"{project_name}_{Path(doc_name).stem}_prompt{prompt_num}"
                    prompt = self.prompts[f'prompt_{prompt_num}']
                    content = doc_data.get('content', '')
                    
                    batch_request = self._create_batch_request(custom_id, prompt, content)
                    batch_requests.append(batch_request)
                    
                    # Mapear n√∫mero de prompt a tipo
                    prompt_types = {1: "auditoria", 2: "desembolsos", 3: "productos"}
                    prompts_applied.append(prompt_types[prompt_num])
                    
                    self.logger.info(f"üìÑ A√±adido al batch: {custom_id} (Prefijo: {prefix})")
            
            # A√±adir informaci√≥n del documento solo si se aplicaron prompts
            if prompts_applied:
                documents_info.append({
                    "document_name": doc_name,
                    "document_type": doc_type,
                    "subfolder": subfolder,
                    "prefix": prefix,
                    "prompts_applied": prompts_applied,
                    "processed_at": datetime.now().isoformat()
                })
                self.logger.info(f"üìÑ Documento agregado: {doc_name} (prompts: {prompts_applied})")
            else:
                self.logger.info(f"‚è≠Ô∏è Saltando documento: {doc_name} (no aplica ning√∫n prompt)")
            
        except Exception as e:
            self.logger.error(f"Error procesando documento {doc_name}: {str(e)}")
            raise

    def _add_document_to_batch(self, doc_path: str, project_name: str, batch_requests: List[Dict], documents_info: List[Dict]):
        """
        Agrega un documento al batch con los prompts aplicables.
        
        Args:
            doc_path: Ruta al documento
            project_name: Nombre del proyecto
            batch_requests: Lista de requests del batch
            documents_info: Lista de informaci√≥n de documentos
        """
        try:
            # Cargar contenido del documento
            with open(doc_path, 'r', encoding='utf-8') as f:
                document_content = json.load(f)
            
            document_content['project_name'] = project_name
            content_text = document_content.get('content', '')
            
            # Extraer informaci√≥n del documento
            document_name = document_content.get('document_name', document_content.get('filename', Path(doc_path).stem))
            chunk_index = None
            if '_chunk_' in str(doc_path):
                chunk_match = re.search(r'_chunk_(\d+)', str(doc_path))
                if chunk_match:
                    chunk_index = int(chunk_match.group(1))
            
            doc_info = {
                "document_name": document_name,
                "file_path": doc_path,
                "chunk_index": chunk_index,
                "prefix": self._get_document_prefix(document_content),
                "prompts_applied": []
            }
            
            # Verificar y agregar prompts aplicables
            prompts = [
                (1, "auditoria", self.prompt_auditoria),
                (2, "desembolsos", self.prompt_desembolsos),
                (3, "productos", self.prompt_productos)
            ]
            
            for prompt_num, prompt_type, prompt_text in prompts:
                if self._should_process_with_prompt(document_content, prompt_num):
                    custom_id = f"{project_name}_{document_name}_{prompt_type}"
                    if chunk_index is not None:
                        custom_id += f"_chunk_{chunk_index:03d}"
                    
                    request = self._create_batch_request(custom_id, prompt_text, content_text)
                    batch_requests.append(request)
                    doc_info["prompts_applied"].append(prompt_type)
            
            if doc_info["prompts_applied"]:
                documents_info.append(doc_info)
                self.logger.info(f"üìÑ Agregado al batch: {document_name} (prompts: {doc_info['prompts_applied']})")
            else:
                self.logger.info(f"‚è≠Ô∏è Saltando documento: {document_name} (no aplica ning√∫n prompt)")
                
        except Exception as e:
            self.logger.error(f"Error procesando documento {doc_path}: {str(e)}")
            raise