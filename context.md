# Context - Sistema de An√°lisis de Documentos con Agentes IA

## Resumen del Proyecto

Este proyecto implementa un sistema de an√°lisis automatizado de documentos utilizando m√∫ltiples agentes de IA especializados. El sistema procesa documentos grandes mediante chunking inteligente y genera an√°lisis detallados a trav√©s de agentes especializados en auditor√≠as, productos y desembolsos.

## Arquitectura del Sistema

### Estructura de Carpetas
```
Agentes Jen/
‚îú‚îÄ‚îÄ main.py                    # Script principal
‚îú‚îÄ‚îÄ docling_processor.py       # Procesamiento de documentos
‚îú‚îÄ‚îÄ chunking_processor.py      # Divisi√≥n en chunks
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îî‚îÄ‚îÄ agents.py             # Definici√≥n de agentes
‚îú‚îÄ‚îÄ tasks/
‚îÇ   ‚îî‚îÄ‚îÄ task.py               # Definici√≥n de tareas
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ settings.py           # Configuraciones
‚îú‚îÄ‚îÄ input_docs/               # Documentos de entrada
‚îÇ   ‚îî‚îÄ‚îÄ {project_name}/
‚îî‚îÄ‚îÄ output_docs/              # Documentos de salida
    ‚îî‚îÄ‚îÄ {project_name}/
        ‚îú‚îÄ‚îÄ docs/             # Chunks y documentos procesados
        ‚îî‚îÄ‚îÄ agents_output/    # JSONs individuales de agentes
```

### Flujo de Procesamiento

1. **Procesamiento Docling**: Extrae y convierte documentos a formato markdown
2. **Chunking Inteligente**: Divide documentos grandes en chunks de m√°ximo 200,000 tokens
3. **An√°lisis por Agentes**: Cada chunk es procesado por:
   - Agentes B√°sicos: Auditor√≠as, Productos, Desembolsos
   - Agentes Expertos: Versiones especializadas de cada agente b√°sico
4. **Consolidaci√≥n**: Agente concatenador unifica todos los resultados

## Modificaciones Implementadas

### ‚úÖ Completadas

#### 1. Estructura de Carpetas Optimizada
- **Archivo**: `main.py` - funci√≥n `create_project_folder_structure()`
- **Cambio**: Creaci√≥n autom√°tica de subcarpetas `docs/` y `agents_output/` dentro de `output_docs/{project_name}/`
- **Prop√≥sito**: Organizar mejor las salidas del sistema

#### 2. Reubicaci√≥n de Archivos de Documentos
- **Archivos**: `docling_processor.py`, `chunking_processor.py`
- **Cambio**: Todos los chunks, concatenados y metadata se guardan en `docs/`
- **Prop√≥sito**: Separar documentos procesados de salidas de agentes

#### 3. JSONs Individuales por Agente
- **Archivo**: `main.py` - funci√≥n `run_analysis_on_chunk()`
- **Cambio**: Cada agente guarda su resultado como JSON individual en `agents_output/`
- **Formato**: `agente_{tipo}_chunk_{index}_output.json`
- **Estructura JSON**:
  ```json
  {
    "agent_name": "Nombre del Agente",
    "phase": "basic_analysis|expert_analysis|final_concatenation",
    "chunk_index": 0,
    "output": "An√°lisis completo...",
    "timestamp": "2025-08-31T19:40:02.880652"
  }
  ```

#### 4. Agente Concatenador con JSON
- **Archivo**: `main.py` - funci√≥n `consolidate_chunk_results()`
- **Cambio**: El agente concatenador tambi√©n guarda su resultado como JSON
- **Archivo**: `agente_concatenador_output.json`
- **Incluye**: Informaci√≥n sobre chunks procesados y timestamp

#### 5. Correcci√≥n de UnboundLocalError
- **Archivo**: `main.py` - funci√≥n `run_full_analysis()`
- **Problema**: Variable `agents_output_dir` no definida en bloques de error
- **Soluci√≥n**: Movida la definici√≥n al inicio de la funci√≥n

#### 6. Optimizaci√≥n del Proceso de Chunking
- **Cambio**: El chunking se ejecuta inmediatamente despu√©s del procesamiento Docling
- **Beneficio**: Evita procesar todo el contenido concatenado, mejora eficiencia

### üîÑ Estado Actual del Sistema

#### Funcionando Correctamente:
- ‚úÖ Estructura de carpetas autom√°tica
- ‚úÖ Procesamiento por chunks (200,000 tokens m√°ximo)
- ‚úÖ Generaci√≥n de JSONs individuales por agente y chunk
- ‚úÖ Guardado en carpetas organizadas (`docs/` y `agents_output/`)
- ‚úÖ Agentes b√°sicos y expertos procesando correctamente

#### Verificado en √öltima Ejecuci√≥n:
- ‚úÖ 30 archivos JSON generados correctamente:
  - 15 archivos de agentes b√°sicos (5 chunks √ó 3 agentes)
  - 15 archivos de agentes expertos (5 chunks √ó 3 agentes)
- ‚úÖ Estructura JSON correcta con todos los campos requeridos
- ‚úÖ Timestamps y metadatos incluidos

### ‚ö†Ô∏è Problemas Identificados

#### 1. Agente Concatenador Incompleto
- **Estado**: El proceso se interrumpe antes de completar la consolidaci√≥n final
- **S√≠ntoma**: Falta el archivo `agente_concatenador_output.json`
- **Causa**: Tareas de CrewAI se quedan en bucle infinito en la fase de consolidaci√≥n
- **Impacto**: No se genera el an√°lisis final unificado

#### 2. Ausencia de Archivos CSV
- **Estado**: No se generan archivos CSV como se esperaba
- **Ubicaci√≥n esperada**: `docs/` junto con los archivos MD
- **Archivos actuales**: Solo se generan archivos `.md` y `.json`

### üìã Tareas Pendientes

#### Alta Prioridad
1. **Resolver Bucle Infinito del Agente Concatenador**
   - Investigar por qu√© las tareas de CrewAI se quedan en "Executing Task..."
   - Posible timeout o configuraci√≥n de agente concatenador
   - Verificar inputs del agente concatenador

2. **Implementar Generaci√≥n de CSV**
   - Determinar qu√© datos deben exportarse a CSV
   - Agregar l√≥gica de exportaci√≥n CSV en el flujo de procesamiento
   - Ubicaci√≥n: carpeta `docs/`

#### Media Prioridad
3. **Optimizar Rendimiento de Agentes**
   - Investigar por qu√© algunos agentes tardan mucho en procesar
   - Considerar timeouts y reintentos

4. **Mejorar Manejo de Errores**
   - Agregar m√°s logging detallado
   - Implementar recuperaci√≥n autom√°tica de fallos

### üîß Comandos de Ejecuci√≥n

```bash
# An√°lisis completo con chunking autom√°tico
python main.py --full-analysis {PROJECT_NAME} --skip-processing

# An√°lisis b√°sico sin chunking
python main.py --basic-analysis {PROJECT_NAME}
```

### üìÅ Archivos de Salida Esperados

#### En `output_docs/{project_name}/docs/`:
- `{project}_chunk_XXX.md` - Chunks individuales
- `{project}_concatenated.md` - Documento completo
- `{project}_metadata.json` - Metadatos del procesamiento
- `{project}_chunking_metadata.json` - Informaci√≥n del chunking
- **PENDIENTE**: Archivos CSV con datos estructurados

#### En `output_docs/{project_name}/agents_output/`:
- `agente_auditorias_chunk_X_output.json`
- `agente_productos_chunk_X_output.json`
- `agente_desembolsos_chunk_X_output.json`
- `agente_experto_auditorias_chunk_X_output.json`
- `agente_experto_productos_chunk_X_output.json`
- `agente_experto_desembolsos_chunk_X_output.json`
- **PENDIENTE**: `agente_concatenador_output.json`

### üöÄ Pr√≥ximos Pasos Recomendados

1. **Debugging del Agente Concatenador**:
   - Revisar configuraci√≥n de timeout en CrewAI
   - Verificar inputs que se pasan al agente concatenador
   - Considerar dividir la tarea de consolidaci√≥n en subtareas m√°s peque√±as

2. **Implementaci√≥n de CSV**:
   - Definir qu√© datos extraer (transacciones, auditor√≠as, productos)
   - Crear funci√≥n de exportaci√≥n CSV
   - Integrar en el flujo de procesamiento

3. **Testing Completo**:
   - Ejecutar an√°lisis completo hasta el final
   - Verificar que todos los archivos se generen correctamente
   - Validar calidad de los an√°lisis generados

### üìä M√©tricas del Sistema

- **Chunks procesados**: 5 (de un documento de ~1.96M tokens)
- **Agentes por chunk**: 6 (3 b√°sicos + 3 expertos)
- **Total JSONs generados**: 30 (exitosos)
- **Tiempo de procesamiento**: ~2-3 minutos por chunk
- **L√≠mite de tokens por chunk**: 200,000

---

**√öltima actualizaci√≥n**: 31 de agosto de 2025
**Estado del proyecto**: Funcional con tareas pendientes cr√≠ticas
**Prioridad**: Resolver agente concatenador y generar CSVs